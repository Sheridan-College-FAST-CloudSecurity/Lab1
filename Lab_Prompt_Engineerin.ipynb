{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "259839fc",
      "metadata": {
        "id": "259839fc"
      },
      "source": [
        "# Lab — Prompt Engineering: Giving AI the Right Instructions\n",
        "\n",
        "**Pre-Requisites:**\n",
        "- [Create a Hugging Face account and retrieve access token](https://huggingface.co/docs/hub/en/security-tokens)\n",
        "- [Add the Hugging Face token to your Colab secrets](https://pyimagesearch.com/2025/04/04/configure-your-hugging-face-access-token-in-colab-environment/)\n",
        "\n",
        "**Goal:**  \n",
        "Develop practical skills to structure prompts so that LLMs:\n",
        "\n",
        "- Produce clearer, more constrained, and safer outputs.  \n",
        "- Follow specific roles, formats, and step-by-step reasoning.  \n",
        "- Are less likely to hallucinate or drift off-task in security contexts.\n",
        "\n",
        "\n",
        "Large Language Models (LLMs) like GPT or OPT don’t think — they follow your instructions.\n",
        "- Vague prompts = vague results\n",
        "- Clear, structured prompts = focused, high-quality results\n",
        "\n",
        "You’re not just “asking questions” — you’re **programming with natural language**.\n",
        "\n",
        "---\n",
        "\n",
        "### What is Prompt Engineering?\n",
        "\n",
        "Prompt engineering is the art of **designing the input** to a model in a way that:\n",
        "- Guides its tone and style\n",
        "- Improves relevance and depth\n",
        "- Reduces hallucinations and randomness\n",
        "- Mimics roles, formats, or logic\n",
        "\n",
        "You can shape output dramatically by changing *just a few words* in your input!\n",
        "\n",
        "---\n",
        "\n",
        "**What you're practicing**:\n",
        "- Writing both a *simple* prompt and an *engineered* version\n",
        "- Understanding how prompt structure changes the model’s output\n",
        "- Learning prompt patterns like **role-based prompts**, **output templates**, and **context embedding**\n",
        "\n",
        "**Why this matters**:\n",
        "- Every real-world AI app — from customer support to marketing — depends on good prompts\n",
        "- You can improve output without changing the model, data, or code\n",
        "- Prompting is the easiest and most powerful way to make LLMs useful for *your* goals"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd5c524f",
      "metadata": {
        "id": "dd5c524f"
      },
      "source": [
        "---\n",
        "## 0. Setup\n",
        "\n",
        "Install libraries if needed and load a small model (GPT-2 or a small chat model).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4aada67",
      "metadata": {
        "id": "f4aada67"
      },
      "outputs": [],
      "source": [
        "# If in Colab, uncomment:\n",
        "!pip install -q transformers torch\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb30332d",
      "metadata": {
        "id": "fb30332d"
      },
      "source": [
        "---\n",
        "## 1. Load a Model\n",
        "\n",
        "Here we use `gpt2`, but for better instruction following you may swap it with a small chat-tuned model if available.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d898f501",
      "metadata": {
        "id": "d898f501"
      },
      "outputs": [],
      "source": [
        "model_name = \"facebook/opt-1.3b\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "print(\"Loaded:\", model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "322a9661",
      "metadata": {
        "id": "322a9661"
      },
      "source": [
        "---\n",
        "## 2. Helper Function\n",
        "\n",
        "We use a simple generation helper with modest sampling.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "897c3dce",
      "metadata": {
        "id": "897c3dce"
      },
      "outputs": [],
      "source": [
        "def generate(prompt, max_new_tokens=160, temperature=0.7, top_p=0.9):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            do_sample=True,\n",
        "            temperature=temperature,\n",
        "            top_p=top_p,\n",
        "        )\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc6741fd",
      "metadata": {
        "id": "bc6741fd"
      },
      "source": [
        "---\n",
        "## 3. Naive vs Structured Prompt\n",
        "\n",
        "1. Start with a **basic question** like:  \n",
        "   _“Explain least privilege.”_\n",
        "\n",
        "2. Then create a **prompt-engineered version** using at least one of these templates:\n",
        "   - “Act as a [role]...”  \n",
        "   - “Use the format:...”  \n",
        "   - “Explain it like I’m a beginner…”  \n",
        "   - “Here’s context, now answer: …”\n",
        "\n",
        "3. Generate both completions and compare:\n",
        "   - Which one is clearer?\n",
        "   - Which one gives more useful advice?\n",
        "   - Which one sounds more professional?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "508725a6",
      "metadata": {
        "id": "508725a6"
      },
      "outputs": [],
      "source": [
        "naive_prompt = \"Explain least privilege.\"\n",
        "better_prompt = (\n",
        "    \"You are a cloud security instructor. \"\n",
        "    \"Use short paragraphs, a concrete cloud example, and finish with a 3-item checklist.\"\n",
        "    \"Explain to postgraduate students in a cloud security program.\"\n",
        "    \"Here’s context, now answer: Explain the principle of least privilege \"\n",
        ")\n",
        "\n",
        "for label, p in [(\"Naive prompt\", naive_prompt), (\"Better structured prompt\", better_prompt)]:\n",
        "    print(\"=\" * 80)\n",
        "    print(label)\n",
        "    print(\"=\" * 80)\n",
        "    print(generate(p))\n",
        "    print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38b86c0e",
      "metadata": {
        "id": "38b86c0e"
      },
      "source": [
        "### ✅ TODO 1 – Improve a Prompt Yourself\n",
        "\n",
        "1. Choose a simple security topic (e.g., \"S3 bucket misconfigurations\").  \n",
        "2. Write a naive prompt.  \n",
        "3. Write a more structured, role-based version that specifies audience, format, and constraints.\n",
        "\n",
        "Fill in the TODO cell and compare outputs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e405995",
      "metadata": {
        "id": "1e405995"
      },
      "outputs": [],
      "source": [
        "# TODO: Fill in your own prompts\n",
        "\n",
        "naive = \"TODO: write a very short naive prompt here\"\n",
        "structured = (\n",
        "    \"TODO: rewrite the naive prompt as a detailed instruction. For example, specify:\\n\"\n",
        "    \"- Role (e.g., cloud security engineer)\\n\"\n",
        "    \"- Audience (e.g., junior analysts)\\n\"\n",
        "    \"- Format (e.g., bullet points, checklist)\\n\"\n",
        "    \"- Constraints (e.g., avoid jargon, include one AWS-specific example)\\n\"\n",
        ")\n",
        "\n",
        "for label, p in [(\"Naive\", naive), (\"Structured\", structured)]:\n",
        "    print(\"=\" * 80)\n",
        "    print(label)\n",
        "    print(\"=\" * 80)\n",
        "    print(generate(p))\n",
        "    print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1c716d1",
      "metadata": {
        "id": "d1c716d1"
      },
      "source": [
        "---\n",
        "## 4. Asking for Step-by-Step Reasoning (Conceptual Only)\n",
        "\n",
        "Even if the underlying model is not a “reasoning model”, adding instructions like:\n",
        "\n",
        "- “Think step by step.”  \n",
        "- “First list your assumptions, then propose actions.”  \n",
        "\n",
        "often changes the style of the answer.\n",
        "\n",
        "We will try this on an incident response scenario.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1261e8d3",
      "metadata": {
        "id": "1261e8d3"
      },
      "outputs": [],
      "source": [
        "prompt_plain = (\n",
        "    \"Describe how you would respond to a suspected credential leak in a cloud environment.\"\n",
        ")\n",
        "\n",
        "prompt_step_by_step = (\n",
        "    \"You are an experienced incident responder. Describe how you would respond to a suspected \"\n",
        "    \"credential leak in a cloud environment. Think step by step. First list key assumptions, then \"\n",
        "    \"outline the investigation steps, and finally propose containment and recovery actions.\"\n",
        ")\n",
        "\n",
        "for label, p in [(\"Plain prompt\", prompt_plain), (\"Step-by-step prompt\", prompt_step_by_step)]:\n",
        "    print(\"=\" * 80)\n",
        "    print(label)\n",
        "    print(\"=\" * 80)\n",
        "    print(generate(p))\n",
        "    print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d701f408",
      "metadata": {
        "id": "d701f408"
      },
      "source": [
        "### ✅ TODO 2 – Design a “Runbook-Style” Prompt\n",
        "\n",
        "Create a prompt that asks the model to output a **runbook** for a specific security scenario, e.g.:\n",
        "\n",
        "- \"Suspicious login from unknown country.\"  \n",
        "- \"Public GitHub repo containing secrets.\"\n",
        "\n",
        "Your prompt should specify:\n",
        "\n",
        "- Role (e.g., SOC analyst)  \n",
        "- Format (e.g., headings: Detection, Triage, Containment, Eradication, Recovery)  \n",
        "- Level of detail (e.g., 3–5 bullet points per section)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "552863ae",
      "metadata": {
        "id": "552863ae"
      },
      "outputs": [],
      "source": [
        "# TODO: Design your runbook-style prompt\n",
        "runbook_prompt = (\n",
        "    \"TODO: write a detailed instruction asking the model to output an incident response runbook \"\n",
        "    \"for a scenario of your choice. Specify role, sections, and bullet-point requirements.\"\n",
        ")\n",
        "\n",
        "print(generate(runbook_prompt))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc76e936",
      "metadata": {
        "id": "bc76e936"
      },
      "source": [
        "---\n",
        "## 5. Prompting for Safer Behavior\n",
        "\n",
        "Prompts can also explicitly request **safe, compliant** behavior, for example:\n",
        "\n",
        "- “Do not provide any steps that would violate laws or company policies.”  \n",
        "- “If you are unsure, say you are unsure rather than guessing.”\n",
        "\n",
        "We will compare answers with and without such constraints.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bbba6ec",
      "metadata": {
        "id": "5bbba6ec"
      },
      "outputs": [],
      "source": [
        "unsafe_like_prompt = (\n",
        "    \"Suggest ways to test the security of a web application.\"\n",
        ")\n",
        "\n",
        "safer_prompt = (\n",
        "    \"You are a security consultant. Suggest ways to test the security of a web application. \"\n",
        "    \"Only include methods that are legal and ethical when performed with proper authorization. \"\n",
        "    \"If a method could be illegal without.permission, clearly state that authorization is required.\"\n",
        ")\n",
        "\n",
        "for label, p in [(\"Without safety constraints\", unsafe_like_prompt), (\"With safety constraints\", safer_prompt)]:\n",
        "    print(\"=\" * 80)\n",
        "    print(label)\n",
        "    print(\"=\" * 80)\n",
        "    print(generate(p))\n",
        "    print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e421980",
      "metadata": {
        "id": "4e421980"
      },
      "source": [
        "### ✅ TODO 3 – Add Safety Constraints to Your Own Prompt\n",
        "\n",
        "Take a prompt you wrote earlier in this lab and:\n",
        "\n",
        "1. Add explicit safety/ethics constraints.  \n",
        "2. Compare outputs with and without those lines.\n",
        "\n",
        "Note any differences in:\n",
        "\n",
        "- Wording and disclaimers  \n",
        "- Level of detail in potentially risky steps\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90b8b22a",
      "metadata": {
        "id": "90b8b22a"
      },
      "outputs": [],
      "source": [
        "# TODO: pick one of your previous prompts and add safety constraints\n",
        "original_prompt = \"TODO: paste one of your previous prompts here\"\n",
        "\n",
        "safer_version = (\n",
        "    original_prompt\n",
        "    + \"\\n\\nIMPORTANT: Only suggest actions that are legal, ethical, and appropriate when performed \"\n",
        "      \"with proper authorization. If you are unsure, explain the uncertainty instead of guessing.\"\n",
        ")\n",
        "\n",
        "for label, p in [(\"Original prompt\", original_prompt), (\"Safer version\", safer_version)]:\n",
        "    print(\"=\" * 80)\n",
        "    print(label)\n",
        "    print(\"=\" * 80)\n",
        "    print(generate(p))\n",
        "    print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccca9f24",
      "metadata": {
        "id": "ccca9f24"
      },
      "source": [
        "---\n",
        "## 6. Summary — Prompting as a Security Control\n",
        "\n",
        "In this lab you:\n",
        "\n",
        "- Saw how **structure, roles, and formatting instructions** change outputs.  \n",
        "- Practiced designing prompts for **clearer, more actionable** security guidance.  \n",
        "- Experimented with prompts that explicitly request **safe, ethical** behavior.\n",
        "\n",
        "Prompt engineering cannot replace technical controls, but it is an important **first line of defense** when working with GenAI systems in security-sensitive contexts.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
